{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento dos dados\n",
    "- Esta célula lê o banco de dados de um arquivo .xlsx, este arquivo deve conter pelo menos duas colunas:\n",
    "    - Uma chamada Descrição\n",
    "    - Outra chamada relevância (0 para não relevante, 1 para relevante)\n",
    "- Stopwords\n",
    "    - Stopwords são palavras que não tem significado substancial para o aprendizado de máquina, palavras como:\n",
    "        - O, de, el, de la, etc...\n",
    "    - Após isso, é necessário baixar os stopwords, para que sejam removidos da Descrição para aumentar a eficiência da interpretação do algoritmo\n",
    "        - Stopwords em português e espanhol\n",
    "    - Este passo deve ser feito apenas na primeira execução\n",
    "- É definido uma função para extrair as stopwords da Descrição, remoção de todos os acentos e caracteres especiais, e definir todas as letras como minúsculas\n",
    "- Cria-se uma nova coluna no dataframe com as Descrições Processadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\brun7530\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brun7530\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Descrição Processada</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solicitado el inicio de las maniobras de aisla...</td>\n",
       "      <td>solicitado inicio maniobras aislacion conforme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entrada de la ATE 202307136 para \"Verificar e ...</td>\n",
       "      <td>entrada ate 202307136 verificar solucionar osc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrada de la ATE 202307508 para \"efectuar man...</td>\n",
       "      <td>entrada ate 202307508 efectuar mantenimiento p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conforme IOC_01.002-17, realizada prueba de pr...</td>\n",
       "      <td>conforme ioc_0100217 realizada prueba preparac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dentro del PD 20230128, accionado partida de l...</td>\n",
       "      <td>dentro pd 20230128 accionado partida unidad gi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>Baixa da ATO 202306261 \"Verificar y solucionar...</td>\n",
       "      <td>baixa ato 202306261 verificar solucionar motiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>Atendendo solicitação do sistema, acionado com...</td>\n",
       "      <td>atendendo solicitacao sistema acionado comando...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>Informado por el Despacho de Carga - Bruno, el...</td>\n",
       "      <td>informado despacho carga bruno termino siguien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>Baixa da ATO 202306201  \"Verificar e soluciona...</td>\n",
       "      <td>baixa ato 202306201 verificar solucionar acion...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>Baixa da ATO 202306271 \"Verificar y solucionar...</td>\n",
       "      <td>baixa ato 202306271 verificar solucionar indic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5713 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Descrição  \\\n",
       "0     Solicitado el inicio de las maniobras de aisla...   \n",
       "1     Entrada de la ATE 202307136 para \"Verificar e ...   \n",
       "2     Entrada de la ATE 202307508 para \"efectuar man...   \n",
       "3     Conforme IOC_01.002-17, realizada prueba de pr...   \n",
       "4     Dentro del PD 20230128, accionado partida de l...   \n",
       "...                                                 ...   \n",
       "5708  Baixa da ATO 202306261 \"Verificar y solucionar...   \n",
       "5709  Atendendo solicitação do sistema, acionado com...   \n",
       "5710  Informado por el Despacho de Carga - Bruno, el...   \n",
       "5711  Baixa da ATO 202306201  \"Verificar e soluciona...   \n",
       "5712  Baixa da ATO 202306271 \"Verificar y solucionar...   \n",
       "\n",
       "                                   Descrição Processada  Relevância  \n",
       "0     solicitado inicio maniobras aislacion conforme...           0  \n",
       "1     entrada ate 202307136 verificar solucionar osc...           0  \n",
       "2     entrada ate 202307508 efectuar mantenimiento p...           0  \n",
       "3     conforme ioc_0100217 realizada prueba preparac...           0  \n",
       "4     dentro pd 20230128 accionado partida unidad gi...           0  \n",
       "...                                                 ...         ...  \n",
       "5708  baixa ato 202306261 verificar solucionar motiv...           0  \n",
       "5709  atendendo solicitacao sistema acionado comando...           0  \n",
       "5710  informado despacho carga bruno termino siguien...           1  \n",
       "5711  baixa ato 202306201 verificar solucionar acion...           0  \n",
       "5712  baixa ato 202306271 verificar solucionar indic...           0  \n",
       "\n",
       "[5713 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega banco de dados para treino e teste\n",
    "data = pd.read_excel(\"banco_dados.xlsx\")\n",
    "\n",
    "# Baixe as stopwords e o tokenizador da NLTK (necessário apenas na primeira execução)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# Inicialize o stemmer e as stopwords\n",
    "stemmer = PorterStemmer()\n",
    "# Stepwords em português\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "# Adicionar stopwords para espanhol\n",
    "stop_words.update(stopwords.words('spanish')) \t\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "def preprocess_text(text):\n",
    "    # Remoção de pontuações e caracteres especiais\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Conversão para minúsculas\n",
    "    text = text.lower()\n",
    "    # Remoção de acentos\n",
    "    text = unidecode(text)\n",
    "    # Tokenização\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remoção de stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Junte as palavras novamente em uma string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Aplicar a função de pré-processamento à coluna de descriçãoa\n",
    "data['Descrição Processada'] = data['Descrição'].apply(preprocess_text)\n",
    "display((data[['Descrição', 'Descrição Processada','Relevância']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetorização utilizando TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "1. **Entendimento do Conceito**:\n",
    "   - TF-IDF (Term Frequency-Inverse Document Frequency) é uma técnica para atribuir pesos a cada palavra em um documento com base em sua frequência e sua importância relativa em todo o corpus (conjunto de todos os documentos).\n",
    "   - O objetivo é representar cada documento como um vetor numérico, onde cada componente do vetor corresponde ao peso de uma palavra específica.\n",
    "\n",
    "2. **Cálculo da Frequência dos Termos (TF)**:\n",
    "   - Para cada palavra em um documento, calcula-se a frequência do termo, ou seja, quantas vezes a palavra aparece no documento.\n",
    "   - A fórmula para calcular a frequência do termo é:\n",
    "     $$\n",
    "     TF_{t,d} = \\frac{\\text{Número de vezes que o termo } t \\text{ aparece em } d}{\\text{Número total de termos em } d}\n",
    "     $$\n",
    "   - Isso resulta em um valor entre 0 e 1, indicando a frequência relativa da palavra no documento.\n",
    "\n",
    "3. **Cálculo da Frequência do Documento Inverso (IDF)**:\n",
    "   - Calcula-se o inverso da frequência de documentos que contêm o termo.\n",
    "   - A fórmula para calcular o IDF é:\n",
    "     $$\n",
    "     IDF_t = \\log\\left(\\frac{\\text{Número total de documentos}}{\\text{Número de documentos que contêm o termo } t}\\right)\n",
    "     $$\n",
    "   - O logaritmo é usado para penalizar termos que aparecem em muitos documentos.\n",
    "\n",
    "4. **Cálculo do Produto TF-IDF**:\n",
    "   - O produto TF-IDF de uma palavra é o produto da frequência do termo no documento (TF) e o inverso da frequência do documento (IDF).\n",
    "   - A fórmula é:\n",
    "     $$\n",
    "     TF-IDF_{t,d} = TF_{t,d} \\times IDF_t\n",
    "     $$\n",
    "   - Isso resulta em um valor que representa a importância da palavra no contexto do documento e do corpus.\n",
    "\n",
    "5. **Implementação usando TfidfVectorizer**:\n",
    "   - A classe TfidfVectorizer do scikit-learn implementa a vetorização de texto usando a técnica TF-IDF.\n",
    "   - Passos:\n",
    "     - Criação do vetorizador: Instancie um objeto TfidfVectorizer.\n",
    "     - Ajuste do vetorizador: Use o método fit_transform para ajustar o vetorizador aos dados de treinamento. Isso aprenderá o vocabulário do corpus e calculará os pesos TF-IDF para cada palavra.\n",
    "     - Vetorização dos dados: Use o método transform para transformar os dados de treinamento e teste em vetores TF-IDF.\n",
    "\n",
    "6. **Utilização dos Vetores TF-IDF**:\n",
    "   - Os vetores TF-IDF resultantes são usados como entrada para modelos de aprendizado de máquina, que podem ser treinados e usados para fazer previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X = data[\"Descrição Processada\"]\n",
    "y = data[\"Relevância\"]\n",
    "# 80% treino, 20% teste, 42 para proporção ser randômica e constante, são DataFrames\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vetorização do texto usando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Você pode converter a matriz esparsa em um DataFrame\n",
    "df_train_tfidf = pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instanciação do Modelo de Regressão Logística**:\n",
    "- Inicialmente é criado uma instância do modelo de Regressão Logística usando a classe *LogisticRegression()* do scikit-learn. Este modelo será usado para fazer previsões sobre a relevância das descrições.\n",
    "\n",
    "**Treinamento do Modelo**:\n",
    "- Após isso é ralizado o treinamento do modelo de regressão logística usando o método *fit()*. Este método recebe dois argumentos:\n",
    "  - *X_train_tfidf*: Este é o conjunto de dados de treinamento pré-processado e vetorizado usando o TF-IDF. Ele contém os vetores TF-IDF das descrições de treinamento.\n",
    "  - *y_train*: Este é o vetor de rótulos correspondentes aos dados de treinamento. Cada rótulo indica se a descrição correspondente é relevante (1) ou não relevante (0).\n",
    "- Durante o treinamento, o modelo ajusta os parâmetros (coeficientes) de forma a minimizar a função de perda, que é geralmente a função de entropia cruzada. Isso é feito usando técnicas de otimização, como o gradiente descendente, para ajustar os parâmetros na direção que reduz a função de perda.\n",
    "\n",
    "\n",
    "**Previsões no conjunto de teste e avaliação do modelo**:\n",
    "- Aqui, estamos utilizando o modelo treinado para fazer previsões sobre o conjunto de teste. O método *predict()* é aplicado ao modelo, passando como entrada os vetores TF-IDF do conjunto de teste (*X_test_tfidf*), lembrando que este X é o resultado da vetorização das Descrições teste do Banco de dados. Isso retorna as previsões do modelo para cada descrição de teste.\n",
    "\n",
    "- Após isso, é avaliado o desempenho do modelo utilizando métricas de avaliação. é utilizado a função *accuracy_score()* do scikit-learn para calcular a acurácia do modelo. Ela compara as previsões feitas com os rótulos verdadeiros do conjunto de teste *y_test*. Essa métrica nos dá uma medida de quão preciso é o modelo em suas previsões.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.8285214348206474\n",
      "\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       742\n",
      "           1       0.76      0.76      0.76       401\n",
      "\n",
      "    accuracy                           0.83      1143\n",
      "   macro avg       0.81      0.81      0.81      1143\n",
      "weighted avg       0.83      0.83      0.83      1143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Treinamento do modelo de Regressão Logística, modelo categórico (relevante ou não)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Avaliando o modelo para banco de dados original\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Acurácia do modelo:\", accuracy)\n",
    "print(\"\\nRelatório de classificação:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teste para outras ocorrências**\n",
    "\n",
    "- Existe um banco_testes, com as ocorrências relevantes de outras datas para avaliar a aderência do modelo a outros dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventos acertados 191\n",
      "Total de eventos 233\n",
      "Aderência do modelo 81.97424892703863\n"
     ]
    }
   ],
   "source": [
    "# Testa o desempenho do modelo com um banco de dados teste\n",
    "banco_teste = pd.read_excel('banco_testes.xlsx', usecols=['Descrição', 'Relevância'])\n",
    "banco_teste['Descricao_Processada'] = banco_teste['Descrição'].apply(preprocess_text)\n",
    "aux = 0\n",
    "\n",
    "for index, description in enumerate(banco_teste['Descricao_Processada']):\n",
    "\tnew_description_tfidf = tfidf_vectorizer.transform([description])\n",
    "\tprediction_new = model.predict(new_description_tfidf)\n",
    "\tif banco_teste['Relevância'].iloc[index] == prediction_new:\n",
    "\t\taux += 1\n",
    "\n",
    "# Apresenta a aderência do modelo para banco_testes\n",
    "aderencia = aux*100/len(banco_teste)\n",
    "print('Eventos acertados', aux)\n",
    "print('Total de eventos', len(banco_teste))\n",
    "print('Aderência do modelo', aderencia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
